
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://the-obstacle-is-the-way.github.io/ai-psychiatrist/_archive/specs/07_JUDGE_AGENT/">
      
      
      
      
        
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Spec 07: Judge Agent & Feedback Loop - AI Psychiatrist</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#spec-07-judge-agent-feedback-loop" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="AI Psychiatrist" class="md-header__button md-logo" aria-label="AI Psychiatrist" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AI Psychiatrist
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Spec 07: Judge Agent &amp; Feedback Loop
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/The-Obstacle-Is-The-Way/ai-psychiatrist" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="AI Psychiatrist" class="md-nav__button md-logo" aria-label="AI Psychiatrist" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    AI Psychiatrist
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/The-Obstacle-Is-The-Way/ai-psychiatrist" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AI Psychiatrist Documentation
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
     research
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
     research
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../_research/hypotheses-explained/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Hypotheses Explained: Current State vs Future Improvements
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../_research/hypotheses-for-improvement/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Hypotheses for Improvement: First-Principles Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../_research/master-bug-audit/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MASTER BUG AUDIT
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Architecture
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Architecture
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../architecture/architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Architecture
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../architecture/future-architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Future Architecture: Agent Orchestration Options
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../architecture/pipeline/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Pipeline
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Clinical
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Clinical
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../clinical/clinical-understanding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Clinical Understanding: How This System Works
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../clinical/glossary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Glossary
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../clinical/phq8/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PHQ-8: Patient Health Questionnaire
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../clinical/task-validity/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Task Validity: What Can (and Cannot) Be Inferred from DAIC-WOZ Transcripts
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Configs
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Configs
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../configs/agent-sampling-registry/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Agent Sampling Parameter Registry
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../configs/configuration-philosophy/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Configuration Philosophy
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../configs/configuration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Configuration Reference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Data
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Data
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data/artifact-namespace-registry/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Artifact Namespace Registry
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data/daic-woz-preprocessing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    DAIC-WOZ Transcript Preprocessing (Bias-Aware, Deterministic)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data/daic-woz-schema/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    DAIC-WOZ Dataset Schema
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data/data-splits-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Data Splits Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Developer
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Developer
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer/api-endpoints/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer/dependency-registry/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Dependency Registry
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer/error-handling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Error Handling and Fail-Fast Philosophy
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer/exceptions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Exception Reference (Domain + Runtime)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developer/testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Testing Conventions (Markers, Fixtures, and Test Doubles)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Getting started
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    Getting started
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting-started/quickstart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quickstart Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    Models
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../models/model-registry/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AI Psychiatrist Model Registry
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../models/model-wiring/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Model Wiring: Current State
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Pipeline internals
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            
  
    Pipeline internals
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pipeline-internals/evidence-extraction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Evidence Extraction Mechanism: How It Actually Works
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pipeline-internals/features/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Feature Reference (Non-Archive Canonical)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Preflight checklist
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            
  
    Preflight checklist
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../preflight-checklist/preflight-checklist-few-shot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Preflight Checklist: Few-Shot Reproduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../preflight-checklist/preflight-checklist-zero-shot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Preflight Checklist: Zero-Shot Run
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_12" >
        
          
          <label class="md-nav__link" for="__nav_12" id="__nav_12_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Rag
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_12">
            <span class="md-nav__icon md-icon"></span>
            
  
    Rag
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../rag/artifact-generation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    RAG Artifact Generation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../rag/chunk-scoring/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chunk-Level Scoring (Spec 35) — Schema, Workflow, and Gotchas
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../rag/debugging/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    RAG Debugging (Audit Logs + Guardrails)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../rag/design-rationale/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    RAG Design Rationale
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../rag/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    RAG Overview: Embeddings and Few-Shot Retrieval
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../rag/runtime-features/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    RAG Runtime Features
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_13" >
        
          
          <label class="md-nav__link" for="__nav_13" id="__nav_13_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Results
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_13">
            <span class="md-nav__icon md-icon"></span>
            
  
    Results
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../results/few-shot-analysis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Why Few-Shot May Not Beat Zero-Shot: Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../results/reproduction-results/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Paper Reproduction Results (Current Status)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../results/run-history/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Complete Run History &amp; Statistical Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../results/run-output-schema/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Reproduction Run Output Schema (JSON + Registry)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14" >
        
          
          <label class="md-nav__link" for="__nav_14" id="__nav_14_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Statistics
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14">
            <span class="md-nav__icon md-icon"></span>
            
  
    Statistics
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../statistics/coverage/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Coverage Explained: What It Is and Why It Matters
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../statistics/metrics-and-evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Metrics and Evaluation (Exact Definitions + Output Schema)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../statistics/statistical-methodology-aurc-augrc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Statistical Methodology: AURC/AUGRC for Selective Prediction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#objective" class="md-nav__link">
    <span class="md-ellipsis">
      
        Objective
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#paper-reference" class="md-nav__link">
    <span class="md-ellipsis">
      
        Paper Reference
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#as-is-implementation-repo" class="md-nav__link">
    <span class="md-ellipsis">
      
        As-Is Implementation (Repo)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="As-Is Implementation (Repo)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#demo-judge-used-by-serverpy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Demo Judge (Used by server.py)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#research-feedback-loop-script-not-wired-into-serverpy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Research Feedback Loop Script (Not Wired Into server.py)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#paper-vs-repo-note" class="md-nav__link">
    <span class="md-ellipsis">
      
        Paper vs Repo Note
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deliverables" class="md-nav__link">
    <span class="md-ellipsis">
      
        Deliverables
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#as-is-metric-prompts-verbatim" class="md-nav__link">
    <span class="md-ellipsis">
      
        As-Is Metric Prompts (Verbatim)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1-judge-agent-agentsjudgepy" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Judge Agent (agents/judge.py)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-feedback-loop-service-servicesfeedback_looppy" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Feedback Loop Service (services/feedback_loop.py)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-tests-test_judgepy" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Tests (test_judge.py)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#acceptance-criteria" class="md-nav__link">
    <span class="md-ellipsis">
      
        Acceptance Criteria
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dependencies" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dependencies
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#specs-that-depend-on-this" class="md-nav__link">
    <span class="md-ellipsis">
      
        Specs That Depend on This
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/The-Obstacle-Is-The-Way/ai-psychiatrist/edit/main/docs/_archive/specs/07_JUDGE_AGENT.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/The-Obstacle-Is-The-Way/ai-psychiatrist/raw/main/docs/_archive/specs/07_JUDGE_AGENT.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="spec-07-judge-agent-feedback-loop">Spec 07: Judge Agent &amp; Feedback Loop</h1>
<h2 id="objective">Objective</h2>
<p>Implement the judge agent that evaluates qualitative assessments and the iterative self-refinement feedback loop described in the paper.</p>
<h2 id="paper-reference">Paper Reference</h2>
<ul>
<li><strong>Section 2.3.1</strong>: Judge agent evaluation with 4 metrics</li>
<li><strong>Appendix B</strong>: Metric definitions (specificity, completeness, coherence, accuracy)</li>
<li><strong>Figure 2</strong>: Evaluation scores before/after feedback loop</li>
</ul>
<h2 id="as-is-implementation-repo">As-Is Implementation (Repo)</h2>
<h3 id="demo-judge-used-by-serverpy">Demo Judge (Used by <code>server.py</code>)</h3>
<ul>
<li>File: <code>agents/qualitive_evaluator.py</code></li>
<li>Class: <code>QualitativeEvaluatorAgent</code></li>
<li>Endpoint: <code>POST /api/chat</code> (non-stream)</li>
<li>Default model: <code>"llama3"</code></li>
<li>Options: <code>{"temperature": 0, "top_k": 20, "top_p": 0.9}</code></li>
<li>Behavior: evaluates metrics <strong>once</strong> and returns a dict of <code>{metric: score}</code>; no iterative loop in <code>server.py</code>.</li>
</ul>
<h3 id="research-feedback-loop-script-not-wired-into-serverpy">Research Feedback Loop Script (Not Wired Into <code>server.py</code>)</h3>
<ul>
<li>File: <code>qualitative_assessment/feedback_loop.py</code></li>
<li>Trigger condition: any metric score <code>&lt;= 2</code> (not paper’s <code>&lt; 4</code>)</li>
<li>Max iterations: <code>10</code></li>
<li>Output format expectations differ (it requests <code>Score:</code> then <code>Explanation:</code> and enforces integer-only scores)</li>
</ul>
<h3 id="paper-vs-repo-note">Paper vs Repo Note</h3>
<p>The paper’s feedback loop trigger is “original evaluation score <strong>below four</strong>” with a max of <strong>10</strong> iterations.
The as-is demo server does not implement this loop; only the standalone cluster script implements a loop (with a different threshold).</p>
<h2 id="deliverables">Deliverables</h2>
<ol>
<li><code>src/ai_psychiatrist/agents/judge.py</code> - Judge evaluation agent</li>
<li><code>src/ai_psychiatrist/services/feedback_loop.py</code> - Iterative refinement service</li>
<li><code>tests/unit/agents/test_judge.py</code> - Comprehensive tests</li>
<li><code>tests/integration/test_feedback_loop.py</code> - Integration tests</li>
</ol>
<h2 id="implementation">Implementation</h2>
<h3 id="as-is-metric-prompts-verbatim">As-Is Metric Prompts (Verbatim)</h3>
<p>From <code>agents/qualitive_evaluator.py</code>:</p>
<div class="highlight"><pre><span></span><code><span class="n">coherence_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Evaluate the following qualitative assessment output for COHERENCE only. Consider the qualitative assessment (qualitative_assessment) of the transcript (transcript) and compare qualitative_assessment to the provided transcript.</span>

<span class="s2">            Coherence (1–5): Is the response logically consistent? Mistakes are logically inconsistent statements or contradictions within the assessment.</span>

<span class="s2">            Score from 1-5 solely based on the following criteria:</span>

<span class="s2">             - score of 5 : 0 mistakes</span>
<span class="s2">             - score of 4 : 1-2 mistakes</span>
<span class="s2">             - score of 3 : 3-4 mistakes</span>
<span class="s2">             - score of 2 : 5-6 mistakes</span>
<span class="s2">             - score of 1 : 7 or more mistakes</span>

<span class="s2">            Format your response as:</span>
<span class="s2">            Explanation: [Your rating, as text]</span>
<span class="s2">            Score: [your score, as a number between 1 and 5]</span>

<span class="s2">            ---</span>
<span class="s2">            Here is the transcript:</span>
<span class="s2">            </span><span class="si">{</span><span class="n">transcript</span><span class="si">}</span>

<span class="s2">            Here is the assessment based on the transcript:</span>
<span class="s2">            </span><span class="si">{</span><span class="n">qualitative_output</span><span class="si">}</span>
<span class="s2">            ---&quot;&quot;&quot;</span>

<span class="n">completeness_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Evaluate the following qualitative assessment output for COMPLETENESS only. Compare qualitative_assessment to the provided transcript. Consider the qualitative assessment (qualitative_assessment) of the transcript (transcript) and compare qualitative_assessment to the provided transcript.</span>

<span class="s2">        Completeness (1–5): Does the assessment cover all relevant symptoms, severities, duration/frequency? Mistakes are missed PHQ-8 symptoms, or duration/frequency details.</span>

<span class="s2">        Score from 1-5 solely based on the following criteria:</span>
<span class="s2">         - score of 5 : 0 mistakes</span>
<span class="s2">         - score of 4 : 1-2 mistakes</span>
<span class="s2">         - score of 3 : 3-4 mistakes</span>
<span class="s2">         - score of 2 : 5-6 mistakes</span>
<span class="s2">         - score of 1 : 7 or more mistakes</span>

<span class="s2">        Format your response as:</span>
<span class="s2">        Explanation: [Your rating, as text]</span>
<span class="s2">        Score: [your score, as a number between 1 and 5]</span>

<span class="s2">        Here is the transcript:</span>
<span class="s2">        </span><span class="si">{</span><span class="n">transcript</span><span class="si">}</span>

<span class="s2">        Here is the assessment based on the transcript:</span>
<span class="s2">        </span><span class="si">{</span><span class="n">qualitative_output</span><span class="si">}</span>
<span class="s2">        ---&quot;&quot;&quot;</span>

<span class="n">specificity_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Evaluate the following qualitative assessment output for SPECIFICITY only. Consider the qualitative assessment (qualitative_assessment) of the transcript (transcript) and compare qualitative_assessment to the provided transcript.</span>

<span class="s2">        Specificity (1–5): Is the assessment specific? Mistakes include using vague/generic statements like &#39;the patient seems depressed&#39;.</span>

<span class="s2">        Score from 1-5 solely based on the following criteria:</span>
<span class="s2">         - score of 5 : 0 mistakes</span>
<span class="s2">         - score of 4 : 1-2 mistakes</span>
<span class="s2">         - score of 3 : 3-4 mistakes</span>
<span class="s2">         - score of 2 : 5-6 mistakes</span>
<span class="s2">         - score of 1 : 7 or more mistakes</span>

<span class="s2">        Format your response as:</span>
<span class="s2">        Explanation: [Your rating, as text]</span>
<span class="s2">        Score: [your score, as a number between 1 and 5]</span>

<span class="s2">        ---</span>
<span class="s2">        Here is the transcript:</span>
<span class="s2">        </span><span class="si">{</span><span class="n">transcript</span><span class="si">}</span>

<span class="s2">        Here is the assessment based on the transcript:</span>
<span class="s2">        </span><span class="si">{</span><span class="n">qualitative_output</span><span class="si">}</span>
<span class="s2">        ---&quot;&quot;&quot;</span>

<span class="n">accuracy_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Evaluate the following qualitative assessment output for ACCURACY only. Consider the qualitative assessment (qualitative_assessment) of the transcript (transcript) and compare qualitative_assessment to the provided transcript.</span>

<span class="s2">        Accuracy (1–5): Are the signs/symptoms aligned with DSM-5 or PHQ-8? Mistakes are incorrect symptoms or incorrect duration/frequency.</span>

<span class="s2">        Score from 1-5 solely based on the following criteria:</span>
<span class="s2">         - score of 5 : 0 mistakes</span>
<span class="s2">         - score of 4 : 1-2 mistakes</span>
<span class="s2">         - score of 3 : 3-4 mistakes</span>
<span class="s2">         - score of 2 : 5-6 mistakes</span>
<span class="s2">         - score of 1 : 7 or more mistakes</span>

<span class="s2">        Format your response as:</span>
<span class="s2">        Explanation: [Your rating, as text]</span>
<span class="s2">        Score: [your score, as a number between 1 and 5]</span>

<span class="s2">        ---</span>
<span class="s2">        Here is the transcript:</span>
<span class="s2">        </span><span class="si">{</span><span class="n">transcript</span><span class="si">}</span>

<span class="s2">        Here is the assessment based on the transcript:</span>
<span class="s2">        </span><span class="si">{</span><span class="n">qualitative_output</span><span class="si">}</span>
<span class="s2">        ---&quot;&quot;&quot;</span>
</code></pre></div>
<h3 id="1-judge-agent-agentsjudgepy">1. Judge Agent (agents/judge.py)</h3>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;Judge agent for evaluating qualitative assessments.&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TYPE_CHECKING</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.domain.entities</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">QualitativeAssessment</span><span class="p">,</span>
    <span class="n">QualitativeEvaluation</span><span class="p">,</span>
    <span class="n">Transcript</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.domain.enums</span><span class="w"> </span><span class="kn">import</span> <span class="n">EvaluationMetric</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.domain.exceptions</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLMError</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.domain.value_objects</span><span class="w"> </span><span class="kn">import</span> <span class="n">EvaluationScore</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.infrastructure.llm.responses</span><span class="w"> </span><span class="kn">import</span> <span class="n">extract_score_from_text</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.infrastructure.logging</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_logger</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.infrastructure.llm.responses</span><span class="w"> </span><span class="kn">import</span> <span class="n">SimpleChatClient</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="c1"># Metric definitions from Appendix B and agents/qualitive_evaluator.py</span>
<span class="n">METRIC_DEFINITIONS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">EvaluationMetric</span><span class="o">.</span><span class="n">SPECIFICITY</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Specificity (1-5): Is the assessment specific? Mistakes include using vague/generic statements like &#39;the patient seems depressed&#39;.</span>

<span class="s2">Score from 1-5 solely based on the following criteria:</span>
<span class="s2"> - score of 5 : 0 mistakes</span>
<span class="s2"> - score of 4 : 1-2 mistakes</span>
<span class="s2"> - score of 3 : 3-4 mistakes</span>
<span class="s2"> - score of 2 : 5-6 mistakes</span>
<span class="s2"> - score of 1 : 7 or more mistakes</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="n">EvaluationMetric</span><span class="o">.</span><span class="n">COMPLETENESS</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Completeness (1-5): Does the assessment cover all relevant symptoms, severities, duration/frequency? Mistakes are missed PHQ-8 symptoms, or duration/frequency details.</span>

<span class="s2">Score from 1-5 solely based on the following criteria:</span>
<span class="s2"> - score of 5 : 0 mistakes</span>
<span class="s2"> - score of 4 : 1-2 mistakes</span>
<span class="s2"> - score of 3 : 3-4 mistakes</span>
<span class="s2"> - score of 2 : 5-6 mistakes</span>
<span class="s2"> - score of 1 : 7 or more mistakes</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="n">EvaluationMetric</span><span class="o">.</span><span class="n">COHERENCE</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Coherence (1-5): Is the response logically consistent? Mistakes are logically inconsistent statements or contradictions within the assessment.</span>

<span class="s2">Score from 1-5 solely based on the following criteria:</span>
<span class="s2"> - score of 5 : 0 mistakes</span>
<span class="s2"> - score of 4 : 1-2 mistakes</span>
<span class="s2"> - score of 3 : 3-4 mistakes</span>
<span class="s2"> - score of 2 : 5-6 mistakes</span>
<span class="s2"> - score of 1 : 7 or more mistakes</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="n">EvaluationMetric</span><span class="o">.</span><span class="n">ACCURACY</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Accuracy (1-5): Are the signs/symptoms aligned with DSM-5 or PHQ-8? Mistakes are incorrect symptoms or incorrect duration/frequency.</span>

<span class="s2">Score from 1-5 solely based on the following criteria:</span>
<span class="s2"> - score of 5 : 0 mistakes</span>
<span class="s2"> - score of 4 : 1-2 mistakes</span>
<span class="s2"> - score of 3 : 3-4 mistakes</span>
<span class="s2"> - score of 2 : 5-6 mistakes</span>
<span class="s2"> - score of 1 : 7 or more mistakes</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span><span class="w"> </span><span class="nf">make_evaluation_prompt</span><span class="p">(</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">EvaluationMetric</span><span class="p">,</span>
    <span class="n">transcript</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">assessment</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate evaluation prompt for a specific metric.</span>

<span class="sd">    Args:</span>
<span class="sd">        metric: Evaluation metric to assess.</span>
<span class="sd">        transcript: Original interview transcript.</span>
<span class="sd">        assessment: Qualitative assessment to evaluate.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Formatted evaluation prompt.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">definition</span> <span class="o">=</span> <span class="n">METRIC_DEFINITIONS</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span>

    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Evaluate the following qualitative assessment output for </span><span class="si">{</span><span class="n">metric</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2"> only. Consider the qualitative assessment (qualitative_assessment) of the transcript (transcript) and compare qualitative_assessment to the provided transcript.</span>

<span class="si">{</span><span class="n">definition</span><span class="si">}</span>

<span class="s2">Format your response as:</span>
<span class="s2">Explanation: [Your rating, as text]</span>
<span class="s2">Score: [your score, as a number between 1 and 5]</span>

<span class="s2">---</span>
<span class="s2">Here is the transcript:</span>
<span class="si">{</span><span class="n">transcript</span><span class="si">}</span>

<span class="s2">Here is the assessment based on the transcript:</span>
<span class="si">{</span><span class="n">assessment</span><span class="si">}</span>
<span class="s2">---&quot;&quot;&quot;</span>


<span class="k">class</span><span class="w"> </span><span class="nc">JudgeAgent</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Agent for evaluating qualitative assessments.</span>

<span class="sd">    Implements the LLM-as-a-judge approach described in Section 2.3.1.</span>
<span class="sd">    Evaluates assessments on 4 metrics using a 5-point Likert scale.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_client</span><span class="p">:</span> <span class="n">SimpleChatClient</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize judge agent.</span>

<span class="sd">        Args:</span>
<span class="sd">            llm_client: LLM client for evaluations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_llm_client</span> <span class="o">=</span> <span class="n">llm_client</span>

    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">assessment</span><span class="p">:</span> <span class="n">QualitativeAssessment</span><span class="p">,</span>
        <span class="n">transcript</span><span class="p">:</span> <span class="n">Transcript</span><span class="p">,</span>
        <span class="n">iteration</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">QualitativeEvaluation</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate a qualitative assessment on all metrics.</span>

<span class="sd">        Args:</span>
<span class="sd">            assessment: Qualitative assessment to evaluate.</span>
<span class="sd">            transcript: Original transcript for reference.</span>
<span class="sd">            iteration: Current feedback loop iteration (0 = initial).</span>

<span class="sd">        Returns:</span>
<span class="sd">            QualitativeEvaluation with scores for all metrics.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Starting qualitative evaluation&quot;</span><span class="p">,</span>
            <span class="n">participant_id</span><span class="o">=</span><span class="n">transcript</span><span class="o">.</span><span class="n">participant_id</span><span class="p">,</span>
            <span class="n">iteration</span><span class="o">=</span><span class="n">iteration</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">scores</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="n">EvaluationMetric</span><span class="p">,</span> <span class="n">EvaluationScore</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">EvaluationMetric</span><span class="o">.</span><span class="n">all_metrics</span><span class="p">():</span>
            <span class="n">score</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_metric</span><span class="p">(</span>
                <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
                <span class="n">transcript</span><span class="o">=</span><span class="n">transcript</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
                <span class="n">assessment</span><span class="o">=</span><span class="n">assessment</span><span class="o">.</span><span class="n">full_text</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">scores</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span> <span class="o">=</span> <span class="n">score</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                <span class="s2">&quot;Metric evaluated&quot;</span><span class="p">,</span>
                <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                <span class="n">score</span><span class="o">=</span><span class="n">score</span><span class="o">.</span><span class="n">score</span><span class="p">,</span>
                <span class="n">participant_id</span><span class="o">=</span><span class="n">transcript</span><span class="o">.</span><span class="n">participant_id</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">evaluation</span> <span class="o">=</span> <span class="n">QualitativeEvaluation</span><span class="p">(</span>
            <span class="n">scores</span><span class="o">=</span><span class="n">scores</span><span class="p">,</span>
            <span class="n">assessment_id</span><span class="o">=</span><span class="n">assessment</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="n">iteration</span><span class="o">=</span><span class="n">iteration</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Evaluation complete&quot;</span><span class="p">,</span>
            <span class="n">participant_id</span><span class="o">=</span><span class="n">transcript</span><span class="o">.</span><span class="n">participant_id</span><span class="p">,</span>
            <span class="n">average_score</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">average_score</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">low_scores</span><span class="o">=</span><span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">low_scores</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">evaluation</span>

    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_evaluate_metric</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">metric</span><span class="p">:</span> <span class="n">EvaluationMetric</span><span class="p">,</span>
        <span class="n">transcript</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">assessment</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EvaluationScore</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate a single metric.</span>

<span class="sd">        Args:</span>
<span class="sd">            metric: Metric to evaluate.</span>
<span class="sd">            transcript: Original transcript text.</span>
<span class="sd">            assessment: Assessment text to evaluate.</span>

<span class="sd">        Returns:</span>
<span class="sd">            EvaluationScore for the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="n">make_evaluation_prompt</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">transcript</span><span class="p">,</span> <span class="n">assessment</span><span class="p">)</span>

        <span class="c1"># Note: The original implementation used temperature=0, top_k=20, top_p=0.9</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_llm_client</span><span class="o">.</span><span class="n">simple_chat</span><span class="p">(</span>
                <span class="n">user_prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="n">LLMError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                <span class="s2">&quot;LLM call failed during metric evaluation&quot;</span><span class="p">,</span>
                <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                <span class="n">error</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">EvaluationScore</span><span class="p">(</span>
                <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
                <span class="n">score</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;LLM evaluation failed; default score used.&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Extract score from response</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">extract_score_from_text</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>

        <span class="c1"># Default to 3 if extraction fails</span>
        <span class="k">if</span> <span class="n">score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Could not extract score, defaulting to 3&quot;</span><span class="p">,</span>
                <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                <span class="n">response_preview</span><span class="o">=</span><span class="n">response</span><span class="p">[:</span><span class="mi">200</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="mi">3</span>

        <span class="k">return</span> <span class="n">EvaluationScore</span><span class="p">(</span>
            <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
            <span class="n">score</span><span class="o">=</span><span class="n">score</span><span class="p">,</span>
            <span class="n">explanation</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_feedback_for_low_scores</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">evaluation</span><span class="p">:</span> <span class="n">QualitativeEvaluation</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract feedback text for low-scoring metrics.</span>

<span class="sd">        Args:</span>
<span class="sd">            evaluation: Evaluation with scores.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary of metric name -&gt; feedback explanation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">feedback</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">low_scores</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">get_score</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>
            <span class="n">feedback</span><span class="p">[</span><span class="n">metric</span><span class="o">.</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Scored </span><span class="si">{</span><span class="n">score</span><span class="o">.</span><span class="n">score</span><span class="si">}</span><span class="s2">/5. </span><span class="si">{</span><span class="n">score</span><span class="o">.</span><span class="n">explanation</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">feedback</span>
</code></pre></div>
<h3 id="2-feedback-loop-service-servicesfeedback_looppy">2. Feedback Loop Service (services/feedback_loop.py)</h3>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;Iterative self-refinement feedback loop service.&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TYPE_CHECKING</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.domain.entities</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">QualitativeAssessment</span><span class="p">,</span>
    <span class="n">QualitativeEvaluation</span><span class="p">,</span>
    <span class="n">Transcript</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.domain.exceptions</span><span class="w"> </span><span class="kn">import</span> <span class="n">MaxIterationsError</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.infrastructure.logging</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_logger</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.agents.judge</span><span class="w"> </span><span class="kn">import</span> <span class="n">JudgeAgent</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.agents.qualitative</span><span class="w"> </span><span class="kn">import</span> <span class="n">QualitativeAssessmentAgent</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">FeedbackLoopSettings</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">FeedbackLoopResult</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Result of the feedback loop refinement process.&quot;&quot;&quot;</span>

    <span class="n">final_assessment</span><span class="p">:</span> <span class="n">QualitativeAssessment</span>
    <span class="n">final_evaluation</span><span class="p">:</span> <span class="n">QualitativeEvaluation</span>
    <span class="n">iterations_used</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">history</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">QualitativeAssessment</span><span class="p">,</span> <span class="n">QualitativeEvaluation</span><span class="p">]]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span>
    <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">improved</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if assessment improved from initial.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">initial_avg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">average_score</span>
        <span class="n">final_avg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_evaluation</span><span class="o">.</span><span class="n">average_score</span>
        <span class="k">return</span> <span class="n">final_avg</span> <span class="o">&gt;</span> <span class="n">initial_avg</span>


<span class="k">class</span><span class="w"> </span><span class="nc">FeedbackLoopService</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Service for iterative assessment refinement.</span>

<span class="sd">    Implements the feedback loop described in Section 2.3.1:</span>
<span class="sd">    1. Generate initial qualitative assessment</span>
<span class="sd">    2. Evaluate with judge agent</span>
<span class="sd">    3. If any score &lt;= threshold, provide feedback and regenerate</span>
<span class="sd">    4. Repeat until all scores acceptable or max iterations reached</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">qualitative_agent</span><span class="p">:</span> <span class="n">QualitativeAssessmentAgent</span><span class="p">,</span>
        <span class="n">judge_agent</span><span class="p">:</span> <span class="n">JudgeAgent</span><span class="p">,</span>
        <span class="n">settings</span><span class="p">:</span> <span class="n">FeedbackLoopSettings</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize feedback loop service.</span>

<span class="sd">        Args:</span>
<span class="sd">            qualitative_agent: Agent for generating assessments.</span>
<span class="sd">            judge_agent: Agent for evaluating assessments.</span>
<span class="sd">            settings: Feedback loop configuration.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_qualitative_agent</span> <span class="o">=</span> <span class="n">qualitative_agent</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_judge_agent</span> <span class="o">=</span> <span class="n">judge_agent</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_max_iterations</span> <span class="o">=</span> <span class="n">settings</span><span class="o">.</span><span class="n">max_iterations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_score_threshold</span> <span class="o">=</span> <span class="n">settings</span><span class="o">.</span><span class="n">score_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_enabled</span> <span class="o">=</span> <span class="n">settings</span><span class="o">.</span><span class="n">enabled</span>

    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transcript</span><span class="p">:</span> <span class="n">Transcript</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FeedbackLoopResult</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run the complete feedback loop for a transcript.</span>

<span class="sd">        Args:</span>
<span class="sd">            transcript: Transcript to assess.</span>

<span class="sd">        Returns:</span>
<span class="sd">            FeedbackLoopResult with final assessment and history.</span>

<span class="sd">        Raises:</span>
<span class="sd">            MaxIterationsError: If max iterations reached without acceptable scores.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Starting feedback loop&quot;</span><span class="p">,</span>
            <span class="n">participant_id</span><span class="o">=</span><span class="n">transcript</span><span class="o">.</span><span class="n">participant_id</span><span class="p">,</span>
            <span class="n">max_iterations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_iterations</span><span class="p">,</span>
            <span class="n">enabled</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_enabled</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Initial assessment</span>
        <span class="n">assessment</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_qualitative_agent</span><span class="o">.</span><span class="n">assess</span><span class="p">(</span><span class="n">transcript</span><span class="p">)</span>
        <span class="n">evaluation</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_judge_agent</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">assessment</span><span class="p">,</span> <span class="n">transcript</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">history</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">QualitativeAssessment</span><span class="p">,</span> <span class="n">QualitativeEvaluation</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">assessment</span><span class="p">,</span> <span class="n">evaluation</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="c1"># Skip refinement if disabled</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enabled</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Feedback loop disabled, returning initial assessment&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">FeedbackLoopResult</span><span class="p">(</span>
                <span class="n">final_assessment</span><span class="o">=</span><span class="n">assessment</span><span class="p">,</span>
                <span class="n">final_evaluation</span><span class="o">=</span><span class="n">evaluation</span><span class="p">,</span>
                <span class="n">iterations_used</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">history</span><span class="o">=</span><span class="n">history</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Refinement loop</span>
        <span class="k">while</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">needs_improvement</span> <span class="ow">and</span> <span class="n">iteration</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_iterations</span><span class="p">:</span>
            <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Refinement iteration&quot;</span><span class="p">,</span>
                <span class="n">iteration</span><span class="o">=</span><span class="n">iteration</span><span class="p">,</span>
                <span class="n">low_scores</span><span class="o">=</span><span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">low_scores</span><span class="p">],</span>
                <span class="n">participant_id</span><span class="o">=</span><span class="n">transcript</span><span class="o">.</span><span class="n">participant_id</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Get feedback for low-scoring metrics</span>
            <span class="n">feedback</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_judge_agent</span><span class="o">.</span><span class="n">get_feedback_for_low_scores</span><span class="p">(</span><span class="n">evaluation</span><span class="p">)</span>

            <span class="c1"># Refine assessment</span>
            <span class="n">assessment</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_qualitative_agent</span><span class="o">.</span><span class="n">refine</span><span class="p">(</span>
                <span class="n">original_assessment</span><span class="o">=</span><span class="n">assessment</span><span class="p">,</span>
                <span class="n">feedback</span><span class="o">=</span><span class="n">feedback</span><span class="p">,</span>
                <span class="n">transcript</span><span class="o">=</span><span class="n">transcript</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Re-evaluate</span>
            <span class="n">evaluation</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_judge_agent</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
                <span class="n">assessment</span><span class="p">,</span> <span class="n">transcript</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=</span><span class="n">iteration</span>
            <span class="p">)</span>

            <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">assessment</span><span class="p">,</span> <span class="n">evaluation</span><span class="p">))</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Refinement complete&quot;</span><span class="p">,</span>
                <span class="n">iteration</span><span class="o">=</span><span class="n">iteration</span><span class="p">,</span>
                <span class="n">average_score</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">average_score</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">needs_improvement</span><span class="o">=</span><span class="n">evaluation</span><span class="o">.</span><span class="n">needs_improvement</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Log final result</span>
        <span class="k">if</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">needs_improvement</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Max iterations reached without full improvement&quot;</span><span class="p">,</span>
                <span class="n">participant_id</span><span class="o">=</span><span class="n">transcript</span><span class="o">.</span><span class="n">participant_id</span><span class="p">,</span>
                <span class="n">iterations</span><span class="o">=</span><span class="n">iteration</span><span class="p">,</span>
                <span class="n">remaining_low</span><span class="o">=</span><span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">low_scores</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Feedback loop successful&quot;</span><span class="p">,</span>
                <span class="n">participant_id</span><span class="o">=</span><span class="n">transcript</span><span class="o">.</span><span class="n">participant_id</span><span class="p">,</span>
                <span class="n">iterations</span><span class="o">=</span><span class="n">iteration</span><span class="p">,</span>
                <span class="n">final_average</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">average_score</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">FeedbackLoopResult</span><span class="p">(</span>
            <span class="n">final_assessment</span><span class="o">=</span><span class="n">assessment</span><span class="p">,</span>
            <span class="n">final_evaluation</span><span class="o">=</span><span class="n">evaluation</span><span class="p">,</span>
            <span class="n">iterations_used</span><span class="o">=</span><span class="n">iteration</span><span class="p">,</span>
            <span class="n">history</span><span class="o">=</span><span class="n">history</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div>
<h3 id="3-tests-test_judgepy">3. Tests (test_judge.py)</h3>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;Tests for judge agent and feedback loop.&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">uuid</span><span class="w"> </span><span class="kn">import</span> <span class="n">uuid4</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.agents.judge</span><span class="w"> </span><span class="kn">import</span> <span class="n">JudgeAgent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.domain.entities</span><span class="w"> </span><span class="kn">import</span> <span class="n">QualitativeAssessment</span><span class="p">,</span> <span class="n">Transcript</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ai_psychiatrist.domain.enums</span><span class="w"> </span><span class="kn">import</span> <span class="n">EvaluationMetric</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tests.fixtures.mock_llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">MockLLMClient</span>


<span class="k">class</span><span class="w"> </span><span class="nc">TestJudgeAgent</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tests for JudgeAgent.&quot;&quot;&quot;</span>

    <span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">mock_high_score_response</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Response indicating high score.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Explanation: The assessment is highly specific.</span>
<span class="s2">Score: 5</span>
<span class="s2">&quot;&quot;&quot;</span>

    <span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">mock_low_score_response</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Response indicating low score.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Explanation: The assessment is too vague.</span>
<span class="s2">Score: 2</span>
<span class="s2">&quot;&quot;&quot;</span>

    <span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample_assessment</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">QualitativeAssessment</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create sample assessment.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">QualitativeAssessment</span><span class="p">(</span>
            <span class="n">overall</span><span class="o">=</span><span class="s2">&quot;Patient shows moderate depression symptoms.&quot;</span><span class="p">,</span>
            <span class="n">phq8_symptoms</span><span class="o">=</span><span class="s2">&quot;Multiple symptoms present.&quot;</span><span class="p">,</span>
            <span class="n">social_factors</span><span class="o">=</span><span class="s2">&quot;Financial stress mentioned.&quot;</span><span class="p">,</span>
            <span class="n">biological_factors</span><span class="o">=</span><span class="s2">&quot;History of depression.&quot;</span><span class="p">,</span>
            <span class="n">risk_factors</span><span class="o">=</span><span class="s2">&quot;Previous suicide attempt.&quot;</span><span class="p">,</span>
            <span class="n">participant_id</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample_transcript</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Transcript</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create sample transcript.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">Transcript</span><span class="p">(</span>
            <span class="n">participant_id</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
            <span class="n">text</span><span class="o">=</span><span class="s2">&quot;Ellie: How are you?</span><span class="se">\n</span><span class="s2">Participant: Not well.&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">asyncio</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">test_evaluate_all_metrics</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">mock_high_score_response</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">sample_assessment</span><span class="p">:</span> <span class="n">QualitativeAssessment</span><span class="p">,</span>
        <span class="n">sample_transcript</span><span class="p">:</span> <span class="n">Transcript</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Should evaluate all 4 metrics.&quot;&quot;&quot;</span>
        <span class="c1"># 4 responses for 4 metrics</span>
        <span class="n">mock_client</span> <span class="o">=</span> <span class="n">MockLLMClient</span><span class="p">(</span>
            <span class="n">chat_responses</span><span class="o">=</span><span class="p">[</span><span class="n">mock_high_score_response</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span>
        <span class="p">)</span>
        <span class="n">agent</span> <span class="o">=</span> <span class="n">JudgeAgent</span><span class="p">(</span><span class="n">llm_client</span><span class="o">=</span><span class="n">mock_client</span><span class="p">)</span>

        <span class="n">evaluation</span> <span class="o">=</span> <span class="k">await</span> <span class="n">agent</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">sample_assessment</span><span class="p">,</span> <span class="n">sample_transcript</span><span class="p">)</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">scores</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>
        <span class="k">assert</span> <span class="n">EvaluationMetric</span><span class="o">.</span><span class="n">COHERENCE</span> <span class="ow">in</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">scores</span>
        <span class="k">assert</span> <span class="n">EvaluationMetric</span><span class="o">.</span><span class="n">COMPLETENESS</span> <span class="ow">in</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">scores</span>
        <span class="k">assert</span> <span class="n">EvaluationMetric</span><span class="o">.</span><span class="n">SPECIFICITY</span> <span class="ow">in</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">scores</span>
        <span class="k">assert</span> <span class="n">EvaluationMetric</span><span class="o">.</span><span class="n">ACCURACY</span> <span class="ow">in</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">scores</span>

    <span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">asyncio</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">test_extracts_scores_correctly</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">mock_high_score_response</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">mock_low_score_response</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">sample_assessment</span><span class="p">:</span> <span class="n">QualitativeAssessment</span><span class="p">,</span>
        <span class="n">sample_transcript</span><span class="p">:</span> <span class="n">Transcript</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Should extract correct numeric scores.&quot;&quot;&quot;</span>
        <span class="c1"># Mix of high and low scores</span>
        <span class="n">mock_client</span> <span class="o">=</span> <span class="n">MockLLMClient</span><span class="p">(</span>
            <span class="n">chat_responses</span><span class="o">=</span><span class="p">[</span>
                <span class="n">mock_high_score_response</span><span class="p">,</span>  <span class="c1"># coherence: 5</span>
                <span class="n">mock_low_score_response</span><span class="p">,</span>   <span class="c1"># completeness: 2</span>
                <span class="n">mock_high_score_response</span><span class="p">,</span>  <span class="c1"># specificity: 5</span>
                <span class="n">mock_low_score_response</span><span class="p">,</span>   <span class="c1"># accuracy: 2</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">agent</span> <span class="o">=</span> <span class="n">JudgeAgent</span><span class="p">(</span><span class="n">llm_client</span><span class="o">=</span><span class="n">mock_client</span><span class="p">)</span>

        <span class="n">evaluation</span> <span class="o">=</span> <span class="k">await</span> <span class="n">agent</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">sample_assessment</span><span class="p">,</span> <span class="n">sample_transcript</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">scores</span><span class="p">[</span><span class="n">EvaluationMetric</span><span class="o">.</span><span class="n">COHERENCE</span><span class="p">]</span><span class="o">.</span><span class="n">score</span> <span class="o">==</span> <span class="mi">5</span>
        <span class="k">assert</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">scores</span><span class="p">[</span><span class="n">EvaluationMetric</span><span class="o">.</span><span class="n">COMPLETENESS</span><span class="p">]</span><span class="o">.</span><span class="n">score</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="k">assert</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">needs_improvement</span>
        <span class="k">assert</span> <span class="n">EvaluationMetric</span><span class="o">.</span><span class="n">COMPLETENESS</span> <span class="ow">in</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">low_scores</span>
</code></pre></div>
<h2 id="acceptance-criteria">Acceptance Criteria</h2>
<ul>
<li>[ ] Evaluates all 4 metrics (coherence, completeness, specificity, accuracy)</li>
<li>[ ] Scores extracted correctly from LLM responses (1-5 scale)</li>
<li>[ ] Feedback loop triggered by configurable threshold:</li>
<li><strong>As-is code</strong>: <code>score &lt;= 2</code> triggers (default for parity)</li>
<li><strong>Paper behavior</strong>: <code>score &lt; 4</code> triggers (set <code>FEEDBACK_SCORE_THRESHOLD=3</code>)</li>
<li>[ ] Feedback loop respects max iterations (default: 10, per paper)</li>
<li>[ ] Assessment improves through iterations</li>
<li>[ ] Can be disabled via configuration (<code>FEEDBACK_ENABLED=false</code>)</li>
<li>[ ] History preserved for analysis</li>
<li>[ ] Comprehensive logging throughout</li>
</ul>
<h2 id="dependencies">Dependencies</h2>
<ul>
<li><strong>Spec 02</strong>: Domain entities (QualitativeEvaluation, EvaluationScore)</li>
<li><strong>Spec 04</strong>: LLM infrastructure</li>
<li><strong>Spec 06</strong>: Qualitative Agent</li>
</ul>
<h2 id="specs-that-depend-on-this">Specs That Depend on This</h2>
<ul>
<li><strong>Spec 11</strong>: Full Pipeline (uses feedback loop)</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.tracking", "navigation.sections", "navigation.footer", "navigation.instant"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>