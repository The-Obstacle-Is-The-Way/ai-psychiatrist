# Spec 09.5: Post-Quantitative Path Integration Checkpoint

## Overview

**Checkpoint Location**: After Spec 09 (Quantitative Agent), before Spec 10 (Meta-Review Agent)

**Purpose**: Validate both qualitative and quantitative paths are working and can integrate before building the meta-review layer.

**Duration**: This is a **MANDATORY PAUSE** for quality review.

## Checkpoint Rationale

At this point, we have completed:
- **Specs 01-04A**: Foundation & Infrastructure
- **Specs 05-07**: Qualitative Path (verified at Checkpoint 07.5)
- **Spec 08**: Embedding Service (vector similarity, few-shot retrieval)
- **Spec 09**: Quantitative Agent (PHQ-8 numerical scoring)

This represents **two complete vertical slices** working together:
1. Qualitative assessment → refined narrative per symptom
2. Quantitative assessment → numerical score (0-3) per symptom

The meta-review agent (Spec 10) will combine these outputs.

## Dual-Path Integration Test

### End-to-End Flow

```
Transcript CSV
    │
    ├──→ TranscriptService ──→ QualitativeAgent ──→ JudgeAgent ──→ Qualitative Assessment
    │                                                                      │
    └──→ EmbeddingService ──→ QuantitativeAgent ───────────────────────────┤
                                                                           ▼
                                                              [Ready for Meta-Review]
```

**Test Command**:
```bash
# Integration test for both paths
pytest tests/integration/test_dual_path_pipeline.py -v

# Manual verification (CLI pipeline is added in Spec 11)
# See tests/integration/test_dual_path_pipeline.py for end-to-end flow
```

### Expected Outputs

1. **Qualitative Assessment** (from Checkpoint 07.5):
   - Narrative for each PHQ-8 symptom
   - Confidence scores
   - Evidence citations

2. **Embedding Retrieval**:
   - k nearest neighbors from reference store
   - Similarity scores
   - Retrieved examples for few-shot prompting

3. **Quantitative Assessment**:
   - Score (0-3) for each PHQ-8 item
   - Evidence for each score
   - Optional "N/A" handling for insufficient evidence

## Bug Hunt Protocol

### P0: Critical (Block all forward progress)

| Issue | Detection Method | Example |
|-------|-----------------|---------|
| Embedding service returns empty results | Integration test | No similar transcripts found |
| Quantitative scores out of range | Validation | Score = 5 (should be 0-3) |
| Few-shot prompts don't include examples | Log inspection | Empty examples section |
| Dual path produces inconsistent results | Cross-validation | Qual says severe, quant says minimal |
| Embedding dimensions mismatch | Runtime error | 4096 vs 1024 |

### P1: High (Fix before next checkpoint)

| Issue | Detection Method | Example |
|-------|-----------------|---------|
| N/A rate too high | Aggregate metrics | >30% N/A responses |
| Retrieval returns same examples for all | Manual inspection | Poor diversity |
| Evidence extraction misses key phrases | Human review | Cited evidence not in transcript |
| Score distribution skewed | Statistical analysis | All scores = 0 or all = 3 |
| Embedding cache not working | Performance test | Always recomputes |

### P2: Medium (Track for later)

| Issue | Detection Method | Example |
|-------|-----------------|---------|
| Embedding space poorly organized | t-SNE visualization | No clustering |
| Retrieval latency too high | Performance test | >100ms per query |
| Quantitative prompts verbose | Review | Could be more concise |

## Quality Gates

### Gate 1: Paper Metrics Baseline

From paper Section 4.2 and Appendix D:

| Metric | Paper Value | Acceptable Range | Check |
|--------|-------------|------------------|-------|
| Few-shot MAE | 0.619 | 0.55 - 0.70 | Required |
| Zero-shot MAE | 0.796 | 0.70 - 0.90 | Reference |
| N/A rate | ~15% | 10% - 25% | Warning if exceeded |
| Embedding dim | 4096 | Exact | Required |
| N examples | 2 | Exact | Required |
| Chunk size | 8 | Exact | Required |

**Verification**:
```bash
# Quantitative evaluation CLI/metrics are added in later specs (Spec 11+)
# For now, rely on integration tests and the legacy research scripts
# under quantitative_assessment/ for MAE calculations.
```

### Gate 2: Embedding Service Health

- [ ] Embeddings computed for all reference transcripts
- [ ] Embedding dimension = 4096 (paper optimal)
- [ ] Cosine similarity computation correct
- [ ] k=2 nearest neighbors retrieval working
- [ ] Cache/persistence working (don't recompute every time)

**Verification**:
```bash
# Test embedding service
pytest tests/unit/services/test_embedding.py -v

# Check reference store (requires embeddings pickle generated out-of-band)
python - <<'PY'
from ai_psychiatrist.config import DataSettings, EmbeddingSettings
from ai_psychiatrist.services.reference_store import ReferenceStore

data = DataSettings()
embed = EmbeddingSettings()
store = ReferenceStore(data, embed)
print(f"Participants: {store.participant_count}")
PY
```

### Gate 3: Quantitative Agent Accuracy

- [ ] All 8 PHQ-8 items scored
- [ ] Scores in valid range (0-3 or N/A)
- [ ] Evidence provided for each score
- [ ] Few-shot examples included in prompt

**Verification**:
```bash
# Run on test set
pytest tests/integration/test_dual_path_pipeline.py -v

# Manual spot check
# CLI pipeline is added in Spec 11; use integration tests for now
```

### Gate 4: Cross-Path Consistency

Qualitative and quantitative assessments should be **consistent but independent**:

| Check | Method | Acceptable |
|-------|--------|------------|
| Both paths cover all 8 symptoms | Output validation | Required |
| High qual confidence → non-zero quant score | Cross-correlation | Correlation > 0.5 |
| N/A in quant → low confidence in qual | Cross-correlation | Expected pattern |
| No shared state between paths | Code review | Required |

## Embedding-Specific Validation

### Reference Store Integrity

```bash
# Check reference embeddings exist
ls -la data/embeddings/

# Verify embedding format
python -c "
import pickle
from pathlib import Path

path = Path('data/embeddings/participant_embedded_transcripts.pkl')
with path.open('rb') as f:
    data = pickle.load(f)

first_pid = next(iter(data))
first_chunk, first_emb = data[first_pid][0]
print(f'Participants: {len(data)}')
print(f'First chunk length: {len(first_chunk)}')
print(f'Embedding dim: {len(first_emb)}')
"
```

### Retrieval Quality

```bash
# Test retrieval diversity (requires embeddings + LLM)
# Use integration tests or add a small local script once CLI is added (Spec 11)

# Should show:
# - 2 distinct neighbors
# - Similarity scores
# - Neighbor participant IDs
```

### Hyperparameter Validation (Paper Appendix D)

| Parameter | Paper Value | Configured Value | Status |
|-----------|-------------|------------------|--------|
| `embedding_dim` | 4096 | Check config.py | |
| `n_examples` | 2 | Check config.py | |
| `chunk_size` | 8 | Check config.py | |
| `similarity_metric` | cosine | Check implementation | |

## Anti-Pattern Detection

### Quantitative Agent Smells

| Smell | Detection | Fix |
|-------|-----------|-----|
| Score extraction via regex | Code review | Use structured output |
| Hardcoded embedding dim | Grep for `4096` | Move to config |
| Direct numpy in agent | Code review | Delegate to service |
| No evidence validation | Output review | Add citation check |
| Synchronous embedding | Performance test | Consider async |

### Embedding Service Smells

| Smell | Detection | Fix |
|-------|-----------|-----|
| Loading full store into memory | Memory profiling | Use lazy loading |
| No caching | Performance test | Add cache layer |
| Recomputing existing embeddings | Log review | Check before compute |
| Mixed concerns (HTTP + math) | Code review | Separate services |

### Grep Commands

```bash
# Check for hardcoded embedding dimensions
grep -rE "4096|1024|2048" src/ai_psychiatrist/

# Check for direct numpy in agents
grep -r "import numpy" src/ai_psychiatrist/agents/

# Check for hardcoded k value
grep -rE "k\s*=\s*[0-9]" src/ai_psychiatrist/

# Check for magic numbers in scoring
grep -rE "score\s*[<>=]+\s*[0-3]" src/ai_psychiatrist/agents/
```

## Technical Debt Inventory Update

### New Debt from Specs 08-09

| Item | Location | Severity | Notes |
|------|----------|----------|-------|
| [Document any new debt] | | | |

### Resolved Debt

| Item | Resolution | Spec |
|------|------------|------|
| [Document resolved items] | | |

### Debt Remaining from Previous Checkpoints

- [ ] Review and update status from 04.5
- [ ] Review and update status from 07.5

## Review Checklist

### Code Quality (Specs 08-09)

- [ ] EmbeddingService has zero linting errors
- [ ] QuantitativeAgent has zero linting errors
- [ ] All public functions have docstrings
- [ ] No `print()` statements
- [ ] No bare `except:` clauses
- [ ] No hardcoded hyperparameters

### Architecture

- [ ] EmbeddingService is independent of agent implementation
- [ ] QuantitativeAgent uses EmbeddingService via injection
- [ ] No circular dependencies
- [ ] Domain entities handle quantitative scores

### Testing

- [ ] Unit tests for EmbeddingService
- [ ] Unit tests for QuantitativeAgent
- [ ] Integration test for few-shot retrieval
- [ ] Integration test for dual-path pipeline
- [ ] No mock abuse

### Paper Parity

- [ ] Embedding dimension matches paper (4096)
- [ ] k-neighbors matches paper (2)
- [ ] Chunk size matches paper (8)
- [ ] MAE within acceptable range of paper (0.619)

## Exit Criteria

**This checkpoint is COMPLETE when:**

1. [ ] All P0 issues resolved
2. [ ] All P1 issues either resolved or documented with plan
3. [ ] Both qualitative and quantitative paths run end-to-end
4. [ ] MAE baseline established (target: ≤0.70)
5. [ ] CI/CD pipeline green
6. [ ] Test coverage ≥ 80% for Specs 08-09 code
7. [ ] Senior review approved
8. [ ] Technical debt inventory updated

## Next Steps

After passing this checkpoint:
1. Proceed to **Spec 10: Meta-Review Agent**
2. Integrate both paths into final assessment
3. Next checkpoint: **Spec 11.5** (after full pipeline)

## Reference Commands

```bash
# Full quality check
make check

# Integration test (both paths)
pytest tests/integration/test_dual_path_pipeline.py -v

# Coverage for specs 08-09 (targeted)
pytest \
  --cov=src/ai_psychiatrist/services/embedding.py \
  --cov=src/ai_psychiatrist/services/reference_store.py \
  --cov=src/ai_psychiatrist/agents/quantitative.py \
  --cov-report=term-missing

# Embedding health check (pickle file)
python - <<'PY'
from ai_psychiatrist.config import DataSettings, EmbeddingSettings
from ai_psychiatrist.services.reference_store import ReferenceStore

data = DataSettings()
embed = EmbeddingSettings()
store = ReferenceStore(data, embed)
print(f"Participants: {store.participant_count}")
PY

# Quantitative evaluation requires CLI pipeline (Spec 11)

# Anti-pattern detection
grep -rE "4096|k\s*=\s*2" src/ai_psychiatrist/
```
