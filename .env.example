# AI Psychiatrist Configuration (Paper-Optimal)
# Copy to .env and fill in values

# ============== Required ==============
OLLAMA_HOST=127.0.0.1
OLLAMA_PORT=11434

# ============== LLM Backend (Optional) ==============
# Default backend is Ollama. Use HuggingFace only if you need official model weights
# that are not available in the Ollama library (e.g., MedGemma).
# LLM_BACKEND=huggingface
# LLM_HF_DEVICE=auto          # auto/cpu/cuda/mps
# LLM_HF_QUANTIZATION=int4    # optional: int4/int8

# ============== LLM Models (Paper-Optimal) ==============
# All agents use Gemma 3 27B (Paper Section 2.2)
# NOTE: MedGemma (Appendix F) has better item-level MAE but makes fewer predictions overall
MODEL_EMBEDDING_MODEL=qwen3-embedding:8b
MODEL_JUDGE_MODEL=gemma3:27b
MODEL_META_REVIEW_MODEL=gemma3:27b
MODEL_QUALITATIVE_MODEL=gemma3:27b
MODEL_QUANTITATIVE_MODEL=gemma3:27b

# Alternative (Appendix F - MedGemma; requires HuggingFace backend for official weights):
# LLM_BACKEND=huggingface
# MODEL_QUANTITATIVE_MODEL=medgemma:27b

# ============== Embedding/Few-Shot (Paper Appendix D) ==============
# Paper optimal hyperparameters:
EMBEDDING_CHUNK_SIZE=8
EMBEDDING_CHUNK_STEP=2
EMBEDDING_DIMENSION=4096
EMBEDDING_TOP_K_REFERENCES=2

# LLM Model Configuration
# ------------------------------------------------------------------------------
# Defaults for clinical reproducibility:
# - All agents: temp=0.0 (Med-PaLM, medRxiv 2025)
# - top_k/top_p: REMOVED (irrelevant at temp=0, best practice is temp only)

MODEL_TEMPERATURE=0.0
# top_k/top_p: NOT SET (irrelevant at temp=0, best practice is temp only)

# ============== Feedback Loop (Paper Section 2.3.1) ==============
FEEDBACK_ENABLED=true
FEEDBACK_MAX_ITERATIONS=10
# Paper: "score below four" triggers refinement (threshold=3 means <4)
FEEDBACK_SCORE_THRESHOLD=3

# ============== Quantitative (SPEC-003) ==============
# Keyword backfill is OFF by default for paper parity (~50% coverage).
# Enable for higher coverage (~74%) at the cost of deviating from paper methodology.
QUANTITATIVE_ENABLE_KEYWORD_BACKFILL=false
QUANTITATIVE_TRACK_NA_REASONS=true
# Max keyword-matched sentences per PHQ-8 item when backfill is enabled.
QUANTITATIVE_KEYWORD_BACKFILL_CAP=3

# ============== Server ==============
API_HOST=0.0.0.0
API_PORT=8000
OLLAMA_TIMEOUT_SECONDS=300

# ============== Logging ==============
LOG_FORMAT=json  # json or console
LOG_LEVEL=INFO
